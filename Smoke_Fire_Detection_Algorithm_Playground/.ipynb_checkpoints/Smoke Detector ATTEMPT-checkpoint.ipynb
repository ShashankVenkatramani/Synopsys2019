{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Video Smoke Detector\n",
    "This program analyzes video frames to look for smoke.\n",
    "It gives a confidence level score between 0% and 100%.\n",
    "To speed up the analysis, the program only analyzes every 10th frame in the source video stream.\n",
    "Thus for example, for a 30 fps video, the video is analyzed 3 times per second.\n",
    "The program is based on the tensorflow retraining tutorial for flower recognition.\n",
    "www.tensorflow.org/tutorials/image_retraining\n",
    "Usage:\n",
    "SOURCE_FILES is a list of videos need to be analyzed.\n",
    "DESTINATION_FILES is a list of the desired output video file names.\n",
    "The program overlays the analysis results at the bottom of the screen.\n",
    "The original videos' audio tracks will be stripped from the output videos.\n",
    "Author: Chen-Yi Liu\n",
    "Date: September 3, 2017\n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "SOURCE_FILES = [\"video1.mp4\",\\\n",
    "                \"video2.mp4\",\\\n",
    "                \"video3.mp4\"]\n",
    "                \n",
    "DESTINATION_FILES = [\"output1.avi\",\\\n",
    "                     \"output2.avi\",\\\n",
    "                     \"output3.avi\"]\n",
    "                     \n",
    "OUTPUT_VIDEO_DIMENSIONS = (720, 1280, 3)\n",
    "METER_IMAGE = \"meter.png\"\n",
    "RENEW_RATE = 1.0\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "meter_image = cv2.imread(METER_IMAGE)\n",
    "\n",
    "\n",
    "# Load the neural network\n",
    "with tf.gfile.FastGFile(\"smoke_or_not.pb\", 'rb') as f:\n",
    "  graph_def = tf.GraphDef()\n",
    "  graph_def.ParseFromString(f.read())\n",
    "  tf.import_graph_def(graph_def, name='')\n",
    "  \n",
    "sess = tf.Session()\n",
    "softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n",
    "\n",
    "# start reading the source videos\n",
    "for i in range(len(SOURCE_FILES)):\n",
    "  video_input = cv2.VideoCapture(SOURCE_FILES[i])  \n",
    "  video_output = cv2.VideoWriter(DESTINATION_FILES[i], fourcc, 30.0, (1280, 720))\n",
    "  print(\"Analysing \", SOURCE_FILES[i])              \n",
    "  \n",
    "  if video_input.isOpened():\n",
    "    # calculate the scaling factor to convert video of any dimensions to HD 720p\n",
    "    # sacrafice the first frame of the video for this task\n",
    "    ret, frame = video_input.read()\n",
    "  \n",
    "    aspect_ratio = frame.shape[1] / frame.shape[0]  \n",
    "    scaling_factor = 0.0\n",
    "    if aspect_ratio < OUTPUT_VIDEO_DIMENSIONS[1]/OUTPUT_VIDEO_DIMENSIONS[0]:\n",
    "      scaling_factor = OUTPUT_VIDEO_DIMENSIONS[0] / frame.shape[0]\n",
    "    else:\n",
    "      scaling_factor = OUTPUT_VIDEO_DIMENSIONS[1] / frame.shape[1]\n",
    "    \n",
    "    half_height = int(frame.shape[0] * scaling_factor / 2)\n",
    "    half_width = int(frame.shape[1] * scaling_factor / 2)\n",
    "    new_height = half_height * 2\n",
    "    new_width = half_width * 2\n",
    "  \n",
    "    # process video\n",
    "    frame_counter = 0\n",
    "    output_frame = np.zeros(OUTPUT_VIDEO_DIMENSIONS, dtype=np.uint8)\n",
    "    confidence = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    max_confidence = 0.0\n",
    "    prev_max_confidence = 0.0\n",
    "    \n",
    "    while(video_input.isOpened()):\n",
    "      ret, frame = video_input.read()\n",
    "\n",
    "      if ret == True:\n",
    "       \n",
    "        # run the smoke analysis\n",
    "        if frame_counter % 10 == 0:\n",
    "          frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # Tensorflow uses RGB whereas OpenCV uses BGR\n",
    "          \n",
    "          # full frame\n",
    "          predictions, = sess.run(softmax_tensor, {'DecodeJpeg:0': frame})\n",
    "          confidence[0] = RENEW_RATE * predictions[0] + (1.0 - RENEW_RATE) * confidence[0]\n",
    "          # the four quadrants\n",
    "          predictions, = sess.run(softmax_tensor, {'DecodeJpeg:0': frame[0:int(frame.shape[0]/2), 0:int(frame.shape[1]/2), :]})\n",
    "          confidence[1] = RENEW_RATE * predictions[0] + (1.0 - RENEW_RATE) * confidence[1]\n",
    "          predictions, = sess.run(softmax_tensor, {'DecodeJpeg:0': frame[int(frame.shape[0]/2):, 0:int(frame.shape[1]/2), :]})\n",
    "          confidence[2] = RENEW_RATE * predictions[0] + (1.0 - RENEW_RATE) * confidence[2]\n",
    "          predictions, = sess.run(softmax_tensor, {'DecodeJpeg:0': frame[0:int(frame.shape[0]/2), int(frame.shape[1]/2):, :]})\n",
    "          confidence[3] = RENEW_RATE * predictions[0] + (1.0 - RENEW_RATE) * confidence[3]\n",
    "          predictions, = sess.run(softmax_tensor, {'DecodeJpeg:0': frame[int(frame.shape[0]/2):, int(frame.shape[1]/2):, :]})\n",
    "          confidence[4] = RENEW_RATE * predictions[0] + (1.0 - RENEW_RATE) * confidence[4]\n",
    "          # center quarter\n",
    "          predictions, = sess.run(softmax_tensor, {'DecodeJpeg:0': frame[int(frame.shape[0]/4):int(frame.shape[0]*3/4),\\\n",
    "                                                                       int(frame.shape[1]/4):int(frame.shape[1]*3/4), :]})\n",
    "          confidence[5] = RENEW_RATE * predictions[0] + (1.0 - RENEW_RATE) * confidence[5]\n",
    "          prev_max_confidence = max_confidence\n",
    "          # the confidence level is calculated as the average of 1) the value of full screen analysis \n",
    "          # AND 2) the maximum value of the four quadrants + central quarter analysis\n",
    "          # this is to make the program more sensitive to smoke that is confined to a small region on the screen\n",
    "          max_confidence = (max(confidence[1:]) + confidence[0]) / 2.0\n",
    "\n",
    "          frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)  # convert back to the OpenCV BGR format\n",
    "\n",
    "        # scale the image to 720p\n",
    "        scaled_frame = cv2.resize(frame, (new_width, new_height))\n",
    "        output_frame[360-half_height:360+half_height, 640-half_width:640+half_width, :] = scaled_frame\n",
    "\n",
    "        # meter readings are interpolated at frames not analzed\n",
    "        # the meter reading at every frame is delayed by 10 frames\n",
    "        meter_reading = (frame_counter%10) / 10 * max_confidence + (1 - (frame_counter%10) / 10) * prev_max_confidence\n",
    "        # put the analysis result on the meter\n",
    "        output_frame[-200:, 440:840] |= meter_image\n",
    "        cv2.putText(output_frame, \"SMOKE\", (585, 680), cv2.FONT_HERSHEY_PLAIN, 2.0, (255,255,255), 2)\n",
    "        cv2.line(output_frame, (640, 700), (640 - int(120*math.cos(meter_reading*3.1416)),\\\n",
    "                                            700 - int(120*math.sin(meter_reading*3.1416))), (50, 255, 0), 4)\n",
    "\n",
    "        # print on the console to show progress\n",
    "        if frame_counter % 30 == 0:\n",
    "          print(frame_counter, meter_reading)      \n",
    "\n",
    "        # add the analyzed frame to the output video\n",
    "        video_output.write(output_frame)\n",
    "        frame_counter += 1\n",
    "  \n",
    "      else:\n",
    "        break\n",
    "\n",
    "  video_input.release()\n",
    "  video_output.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
